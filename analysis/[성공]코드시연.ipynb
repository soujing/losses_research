{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 현재 작업 환경 설정 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/ahnailab/jsj0414/losses_research\n",
      "['/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model/original_ColonFormer', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research/model', '/project/ahnailab/jsj0414/losses_research', '/project/ahnailab/jsj0414/losses_research/model', '/home/jsj0414/.conda/envs/image/lib/python312.zip', '/home/jsj0414/.conda/envs/image/lib/python3.12', '/home/jsj0414/.conda/envs/image/lib/python3.12/lib-dynload', '', '/home/jsj0414/.local/lib/python3.12/site-packages', '/home/jsj0414/.conda/envs/image/lib/python3.12/site-packages', '/home/jsj0414/.conda/envs/image/lib/python3.12/site-packages/setuptools/_vendor', '/tmp/tmpl10qfaf1', './.conda/envs/image/lib/python3.12/site-packages/', './.conda/envs/image/lib/python3.12/site-packages/', './.conda/envs/image/lib/python3.12/site-packages', './.conda/envs/image/lib/python3.12/site-packages/']\n",
      "Model is using: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsj0414/.conda/envs/image/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "%cd /project/ahnailab/jsj0414/losses_research\n",
    "#\n",
    "import mmcv\n",
    "import torch\n",
    "\n",
    "# ColonFormer 폴더까지 포함\n",
    "# sys.path.insert(\n",
    "#     0,\n",
    "#     os.path.abspath(\"/project/ahnailab/jsj0414/losses_research/working_path/model/original_ColonFormer\")\n",
    "# )\n",
    "\n",
    "\n",
    "# colon_lib를 올바르게 import\n",
    "# from colon_lib.models.segmentors.colonformer import ColonFormer\n",
    "print(sys.path)\n",
    "\n",
    "# from model.config import DEVICE\n",
    "torch.cuda.set_device(2)  # 메인 파일에서 GPU 2번을 기본 디바이스로 설정\n",
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Model is using: {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8rAU9PR_6LB"
   },
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files and system\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "# working with images\n",
    "import cv2\n",
    "import imageio\n",
    "import scipy.ndimage\n",
    "# import skimage.transform\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "# sys.path.insert(0, '..')\n",
    "\n",
    "# losses\n",
    "from metrics_loss import *\n",
    "\n",
    "# model 전부 load\n",
    "# import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/ahnailab/jsj0414/losses_research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_segmentation(outputs: torch.Tensor, labels: torch.Tensor, metric, batch_output=False):\n",
    "    # outputs가 dict이거나 tuple일 경우, tensor를 가져옴\n",
    "    if isinstance(outputs, dict):\n",
    "        outputs = outputs['out']\n",
    "    elif isinstance(outputs, tuple):\n",
    "        outputs = outputs[0]\n",
    "\n",
    "    # sigmoid를 적용하여 예측값을 확률(0~1)로 변환\n",
    "    # 만약, 모델에 sigmoid나 이에 상응하는 활성화 함수가 포함되어 있으면 아래 줄을 주석 처리할 것\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "\n",
    "    # 픽셀 별 예측 값을 0.5를 기준으로 0 또는 1로 thresholding\n",
    "    outputs = outputs > 0.5\n",
    "\n",
    "    # binary class의 경우 출력 channel은 1이므로, (BATCH, 1, H, W)의 형식을 가짐\n",
    "    # 따라서, (BATCH, 1, H, W) -> (BATCH, H, W)로 차원을 줄여줌\n",
    "    outputs = outputs.squeeze(1).byte()  # (BATCH, 1, H, W) -> (BATCH, H, W)\n",
    "    labels = labels.squeeze(1).byte()    # (BATCH, 1, H, W) -> (BATCH, H, W)\n",
    "\n",
    "    # SMOOTH는 나눗셈에서 분모가 0인 것을 방지하기 위해 더해주는 값\n",
    "    SMOOTH = 1e-8\n",
    "\n",
    "    if metric == 'iou':\n",
    "        # IoU : intersection / union\n",
    "        intersection = (outputs & labels).float().sum((1, 2))  # (BATCH, H, W)에서 픽셀 단위로 AND 연산 후 합산\n",
    "        union = (outputs | labels).float().sum((1, 2))         # (BATCH, H, W)에서 픽셀 단위로 OR 연산 후 합산\n",
    "        result = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    elif metric == 'dice':\n",
    "        # Dice Coefficient: 2 * intersection / (output + label)\n",
    "        intersection = (outputs & labels).float().sum((1, 2))  # (BATCH, H, W)에서 픽셀 단위로 AND 연산 후 합산\n",
    "        result = (2 * intersection + SMOOTH) / (outputs.float().sum((1, 2)) + labels.float().sum((1, 2)) + SMOOTH)\n",
    "    elif metric == 'precision':\n",
    "        # Precision: TP / (TP + FP)\n",
    "        true_positive = (outputs & labels).float().sum((1, 2))  # True Positive (TP): 예측과 실제가 모두 1인 경우\n",
    "        predicted_positive = outputs.float().sum((1, 2))        # Predicted Positive: 예측이 1인 경우\n",
    "        result = (true_positive + SMOOTH) / (predicted_positive + SMOOTH)\n",
    "    elif metric == 'recall':\n",
    "        # Recall: TP / (TP + FN)\n",
    "        true_positive = (outputs & labels).float().sum((1, 2))  # True Positive (TP): 예측과 실제가 모두 1인 경우\n",
    "        actual_positive = labels.float().sum((1, 2))            # Actual Positive: 실제가 1인 경우\n",
    "        result = (true_positive + SMOOTH) / (actual_positive + SMOOTH)\n",
    "    elif metric == 'f1':\n",
    "        # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        true_positive = (outputs & labels).float().sum((1, 2))  # True Positive (TP): 예측과 실제가 모두 1인 경우\n",
    "        predicted_positive = outputs.float().sum((1, 2))        # Predicted Positive: 예측이 1인 경우\n",
    "        actual_positive = labels.float().sum((1, 2))            # Actual Positive: 실제가 1인 경우\n",
    "        # Precision과 Recall 계산\n",
    "        precision = (true_positive + SMOOTH) / (predicted_positive + SMOOTH)\n",
    "        recall = (true_positive + SMOOTH) / (actual_positive + SMOOTH)\n",
    "        # F1 Score 계산\n",
    "        result = (2 * precision * recall) / (precision + recall + SMOOTH)  \n",
    "\n",
    "    if batch_output:\n",
    "        return result  # shape: [BATCH] : 배치 내 각 이미지별 값 (벡터)\n",
    "    else:\n",
    "        return result.mean()  # shape: float (단일 상수 값) : 배치 내 모든 이미지의 평균 (상수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-idQzI2_6LM"
   },
   "source": [
    "# 데이터셋 클래스 생성\n",
    "> 해당 클래스는 이용하려는 이미지와 라벨의 모든 경로(/data/segmentation/...)의 리스트를 인자로 받는다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1663841626890,
     "user": {
      "displayName": "김동현",
      "userId": "12784596420296644443"
     },
     "user_tz": -540
    },
    "id": "QsLMJcor_6LL"
   },
   "outputs": [],
   "source": [
    "_size = 224, 224\n",
    "resize = transforms.Resize(_size, interpolation=0)\n",
    "\n",
    "# set your transforms \n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(_size, interpolation=0),\n",
    "                           transforms.RandomRotation(180),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(_size, padding = 10), # needed after rotation (with original size)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(_size, interpolation=0),\n",
    "                       ])\n",
    "\n",
    "# Save images to folder and create a custom dataloader that loads them from their path. More involved than method 1 but allows for greater flexibility\n",
    "# Requires 3 functions: __init__ to initialize the object, and __len__ and __get__item for pytorch purposes. More functions can be added as needed, but those 3 are necessary for it to function with pytorch\n",
    "class myDataSet(object):\n",
    "\n",
    "    def __init__(self, path_images, path_masks, transforms):\n",
    "        \"Initialization\"\n",
    "        self.all_path_images = sorted(path_images)\n",
    "        self.all_path_masks = sorted(path_masks)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Returns length of dataset\"\n",
    "        return len(self.all_path_images)  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Return next item of dataset\"\n",
    "        \n",
    "        if torch.is_tensor(index):        # 인덱스가 tensor 형태일 수 있으니 리스트 형태로 바꿔준다.\n",
    "            index = index.tolist()\n",
    "        \n",
    "        # Define path to current image and corresponding mask\n",
    "        path_img = self.all_path_images[index]\n",
    "        path_mask = self.all_path_masks[index]\n",
    "\n",
    "        # Load image and mask:\n",
    "        #     .jpeg has 3 channels, channels recorded last\n",
    "        #     .jpeg records values as intensities from 0 to 255\n",
    "        #     masks for some reason have values different to 0 or 255: 0, 1, 2, 3, 4, 5, 6, 7, 248, 249, 250, 251, 252, 253, 254, 255\n",
    "        img_bgr = cv2.imread(path_img) \n",
    "        img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)  # cv2는 채널이 BGR로 저장된다 -> 출력할 때 RGB로 바꿔줘야함\n",
    "        img = img / 255  # 픽셀 값들을 0~1로 변환한다\n",
    "        \n",
    "        mask = cv2.imread(path_mask)[:, :, 0] / 255  # 마스크의 채널은 1개만 있으면 된다\n",
    "        mask = mask.round() # binarize to 0 or 1 (이진분류)\n",
    "        \n",
    "        # note, resizing happens inside transforms\n",
    "        \n",
    "        # convert to Tensors and fix the dimentions\n",
    "        img = torch.FloatTensor(np.transpose(img, [2, 0 ,1])) # Pytorch uses the channels in the first dimension\n",
    "        mask = torch.FloatTensor(mask).unsqueeze(0) # Adding channel dimension to label\n",
    "        \n",
    "        # apply transforms/augmentation to both image and mask together\n",
    "        sample = torch.cat((img, mask), 0) # insures that the same transform is applied\n",
    "        sample = self.transforms(sample)\n",
    "        img = sample[:img.shape[0], ...]\n",
    "        mask = sample[img.shape[0]:, ...]\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name, split_ratio, random_seed):\n",
    "    df = pd.read_csv('./all_ISIC_reszie_224.csv')\n",
    "    df = pd.DataFrame({col: np.array(df[col]) for col in df.columns})\n",
    "    \n",
    "    image_files = list(df[df['type'] == data_name]['images'])\n",
    "    label_files = list(df[df['type'] == data_name]['labels'])\n",
    "\n",
    "    if len(split_ratio) == 2:  # split_ratio = (train, test)\n",
    "        test_size = split_ratio[1] / sum(split_ratio)\n",
    "        train_images, test_images, train_labels, test_labels = train_test_split(image_files, label_files, test_size=test_size, random_state=random_seed)\n",
    "        return train_images, test_images, train_labels, test_labels\n",
    "        \n",
    "    elif len(split_ratio) == 3:  # split_ratio = (train, validation, test)\n",
    "        trainval2test_size = split_ratio[2] / sum(split_ratio)\n",
    "        trainval_images, test_images, trainval_labels, test_labels = train_test_split(image_files, label_files, test_size=trainval2test_size, random_state=random_seed)\n",
    "        train2val_size = split_ratio[1] / sum(split_ratio[0:2])\n",
    "        train_images, val_images, train_labels, val_labels = train_test_split(trainval_images, trainval_labels, test_size=train2val_size, random_state=random_seed)\n",
    "        return train_images, val_images, test_images, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델을 실행시키는데에 추가적으로 필요한 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model_name):\n",
    "\n",
    "    def get_project_root():\n",
    "        try:\n",
    "            # .py 파일에서 실행될 때\n",
    "            return os.path.dirname(os.path.abspath(__file__))\n",
    "        except NameError:\n",
    "            # Jupyter Notebook에서 실행될 때\n",
    "            return os.getcwd()\n",
    "\n",
    "    \n",
    "    sys.path.insert(\n",
    "    0,\n",
    "    \"/project/ahnailab/jsj0414/losses_research/model\"\n",
    "    )\n",
    "    \n",
    "    model = None  # 기본값을 None으로 설정하여 변수가 초기화되지 않는 상황 방지\n",
    "    \n",
    "    if model_name == 'FCBFormer':\n",
    "        from FCBformer.FCBmodels import FCBFormer\n",
    "        model = FCBFormer(size=224)\n",
    "        \n",
    "    elif model_name == 'EMCADNet':\n",
    "        from EMCAD import EMCADNet\n",
    "        model = EMCADNet(encoder='pvt_v2_b2')\n",
    "\n",
    "    elif model_name == 'ColonSegNet':\n",
    "        from ColonSegNet import CompNet as ColonSegNet\n",
    "        model = ColonSegNet()\n",
    "\n",
    "    elif model_name == 'FCN':\n",
    "        from FCN.models.segmentation.fcn import fcn_resnet101\n",
    "        model = fcn_resnet101(num_classes=1)\n",
    "\n",
    "    elif model_name == 'DeepLab_V3+':\n",
    "        from DeepLab_V3_p.model import DeepLab as DeepLab_V3_p\n",
    "        model = DeepLab_V3_p(backbone='resnet', num_classes=1)\n",
    "\n",
    "    elif model_name == 'ESFPNet':\n",
    "        from ESFPNet.ESFPmodel import ESFPNetStructure\n",
    "        model = ESFPNetStructure(embedding_dim=224)\n",
    "\n",
    "\n",
    "    elif model_name == 'Unet':\n",
    "        from Unet.unet import UNet\n",
    "        model = UNet(n_channels=3, n_classes=1, pretrained=True)\n",
    "\n",
    "    elif model_name == 'UNet++':\n",
    "        from nnunet import Nested_UNet as UNet2p\n",
    "        model = UNet2p(1, 3)\n",
    "\n",
    "    elif model_name == 'DuckNet':\n",
    "        from duck_net import DuckNet\n",
    "        model = DuckNet(in_channels=3, out_channels=1, depth=5, init_features=34, normalization='batch', interpolation='nearest', out_activation=None, use_multiplier=True)\n",
    "        import torch.nn as nn\n",
    "        model.apply(lambda m: nn.init.kaiming_uniform_(m.weight) if type(m) == nn.Conv2d else None) # default init is xaiver uniform        \n",
    "\n",
    "    elif model_name == 'ColonFormer':\n",
    "        # 이 파일(init_model.py 또는 notebook이 아니라,\n",
    "        # \"이 코드를 포함한 파일\" 기준)\n",
    "        PROJECT_ROOT = get_project_root()\n",
    "        \n",
    "        COLONFORMER_ROOT = os.path.join(\n",
    "            PROJECT_ROOT,\n",
    "            \"model\",\n",
    "            \"original_ColonFormer\"\n",
    "        )\n",
    "        \n",
    "        if COLONFORMER_ROOT not in sys.path:\n",
    "            sys.path.insert(0, COLONFORMER_ROOT)\n",
    "            \n",
    "        from colon_lib.models.segmentors.colonformer import ColonFormer\n",
    "        \n",
    "        backbone=dict(type='mit_b3',style='pythorch')\n",
    "        \n",
    "        decode_head=dict(type='UPerHead', in_channels=[64], in_index=[0], channels=128, dropout_ratio=0.1,\n",
    "                            num_classes=1, norm_cfg=dict(type='BN', requires_grad=True), align_corners=False,decoder_params=dict(embed_dim=768),\n",
    "                            loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0))\n",
    "        \n",
    "        pretrained = os.path.join(\n",
    "            COLONFORMER_ROOT,\n",
    "            \"colon_lib\",\n",
    "            \"pretrained\",\n",
    "            \"mit_b3.pth\"\n",
    "        )\n",
    "        \n",
    "        model = ColonFormer(backbone,decode_head = decode_head,\n",
    "                        neck=None,\n",
    "                        auxiliary_head=None,\n",
    "                        train_cfg=dict(),\n",
    "                        test_cfg=dict(mode='whole'),\n",
    "                        pretrained= pretrained)\n",
    "\n",
    "    elif model_name == 'caranet':\n",
    "        from caranet import caranet\n",
    "        \n",
    "        model = caranet()\n",
    "\n",
    "    elif model_name == 'FAT_Net':\n",
    "        from FATNet_model.FAT_Net import FAT_Net\n",
    "        model = FAT_Net()\n",
    "\n",
    "    # 모델이 None인 경우, 예외 처리\n",
    "    if model is None:\n",
    "        raise ValueError(f\"모델 이름 '{model_name}'이 잘못되었거나 모델을 로드할 수 없습니다.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 04:29:28,597 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: head.weight, head.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColonFormer load가능\n",
      "\n",
      "DuckNet load가능\n",
      "\n",
      "UNet++ load가능\n",
      "\n",
      "Unet load가능\n",
      "\n",
      "ESFPNet load가능\n",
      "\n",
      "DeepLab_V3+ load가능\n",
      "\n",
      "FCN load가능\n",
      "\n",
      "ColonSegNet load가능\n",
      "\n",
      "Model pvt_v2_b2 backbone:  created, param count: 24849856\n",
      "Model EMCAD decoder:  created, param count: 1913515\n",
      "EMCADNet load가능\n",
      "\n",
      "FCBFormer load가능\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsj0414/.conda/envs/image/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jsj0414/.conda/envs/image/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAT_Net load가능\n",
      "\n",
      "caranet load가능\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['ColonFormer','DuckNet','UNet++','Unet' ,'ESFPNet','DeepLab_V3+','FCN'\n",
    "         ,'ColonSegNet','EMCADNet','FCBFormer','FAT_Net','caranet'] # 'ColonFormer',\n",
    "for model in models:\n",
    "    try: \n",
    "        init_model(model)\n",
    "        print(f'{model} load가능\\n')\n",
    "    except Exception as e:\n",
    "        print(f'{model} 로드 중 에러발생, 모델 로드 불가: {e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill -9 8412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(loss_name):\n",
    "    dic_name2func={\n",
    "        \"IoUWithGaussianLoss\" : IoUWithGaussianLoss,\n",
    "        \"BCEWithGaussianLoss\": BCEWithGaussianLoss,\n",
    "        \"DiceWithGaussianLoss\": DiceWithGaussianLoss,\n",
    "        \"FocalWithGaussianLoss\" : FocalWithGaussianLoss,\n",
    "        \n",
    "        \"FocalWithSSIMLoss\": FocalWithSSIMLoss,\n",
    "        \"IoUWithSSIMLoss\" : IoUWithSSIMLoss,\n",
    "        \"DiceWithSSIMLoss\" : DiceWithSSIMLoss,\n",
    "        \"BCEWithSSIMLoss\" : BCEWithSSIMLoss,\n",
    "        \n",
    "        \"FocalWithContextualLoss\": FocalWithContextualLoss,\n",
    "        \"BCEWithContextualLoss\": BCEWithContextualLoss,\n",
    "        \"IoUWithContextualLoss\" : IoUWithContextualLoss,\n",
    "        \"DiceWithContextualLoss\" : DiceWithContextualLoss,\n",
    "        \n",
    "        \"IoUWithTVLoss_tar\": IoUWithTVLoss_tar,\n",
    "        \"FocalWithTVLoss_tar\" : FocalWithTVLoss_tar,\n",
    "        \"DiceWithTVLoss_tar\" : DiceWithTVLoss_tar,\n",
    "        \"BCEWithTVLoss_tar\" : BCEWithTVLoss_tar,\n",
    "        \n",
    "        \n",
    "        \"FocalWithEdgeLoss\": FocalWithEdgeLoss,\n",
    "        \"BCEWithEdgeLoss\": BCEWithEdgeLoss,\n",
    "        \"IoUWithEdgeLoss\" : IoUWithEdgeLoss,\n",
    "        \"DiceWithEdgeLoss\" : DiceWithEdgeLoss,\n",
    "        \n",
    "    \n",
    "        'IoULoss' : IoULoss,\n",
    "        'DiceLoss' : DiceLoss,\n",
    "        'BCELoss' : BCELoss,\n",
    "        'FocalLoss' : FocalLoss,\n",
    "        'IoUDiceLoss' : IoUDiceLoss,\n",
    "        'IoUBCELoss' : IoUBCELoss,\n",
    "        'IoUFocalLoss' : IoUFocalLoss,\n",
    "        'DiceBCELoss' : DiceBCELoss,\n",
    "        'DiceFocalLoss' : DiceFocalLoss,\n",
    "        'BCEFocalLoss' : BCEFocalLoss,\n",
    "    }\n",
    "    return dic_name2func[loss_name]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFBEH3fL_6LS"
   },
   "source": [
    "# 3. 모델 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_names,    # e.g. ['breast-cancer-benign']\n",
    "        model_names,   # e.g. ['FCBFormer']\n",
    "        loss_names,    # e.g. ['DiceBCELoss']\n",
    "        iters = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "        split_ratio = [0.6, 0.2, 0.2],\n",
    "        base_random_seed = 42, \n",
    "        epochs = 200, \n",
    "        patience = 50, \n",
    "        BATCH_SIZE = 8,\n",
    "        result_file = None\n",
    "       ):\n",
    "    DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\") # select device for training, i.e. gpu or cpu\n",
    "\n",
    "    import itertools\n",
    "    for data_name, model_name, loss_name, iter in itertools.product(data_names, model_names, loss_names, iters):\n",
    "        if base_random_seed != None:\n",
    "            random_seed = base_random_seed + iter\n",
    "            random.seed(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "            torch.manual_seed(random_seed)\n",
    "            torch.cuda.manual_seed(random_seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "\n",
    "        # load data\n",
    "        train_images, val_images, test_images, train_labels, val_labels, test_labels = load_data(data_name, split_ratio=split_ratio, random_seed=random_seed)\n",
    "\n",
    "        custom_dataset_train = myDataSet(train_images, train_labels, transforms=test_transforms)\n",
    "        custom_dataset_val = myDataSet(val_images, val_labels, transforms=test_transforms)\n",
    "        custom_dataset_test = myDataSet(test_images, test_labels, transforms=test_transforms)\n",
    "       \n",
    "        dataloader_train = torch.utils.data.DataLoader(custom_dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "        dataloader_val = torch.utils.data.DataLoader(custom_dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "        dataloader_test = torch.utils.data.DataLoader(custom_dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "        print(f'Experiment env - \\n'+\n",
    "              f'\\t - data name : {data_name}\\n' +\n",
    "              f'\\t - the  ratio of dataset : total/train/val/test = {sum(split_ratio)}/{split_ratio[0]}/{split_ratio[1]}/{split_ratio[2]}\\n' +\n",
    "              f'\\t - the number of dataset : total/train/val/test = {len(custom_dataset_train)+len(custom_dataset_val)+len(custom_dataset_test)}/{len(custom_dataset_train)}/{len(custom_dataset_val)}/{len(custom_dataset_test)}\\n' +\n",
    "              f'\\t - model name : {model_name}\\n' +\n",
    "              f'\\t - loss name : {loss_name}\\n' +\n",
    "              f'\\t - iter : {iter} of {iters}\\n' +\n",
    "              f'\\t - random_seed : {random_seed}\\n' +\n",
    "              f'\\t - epochs & patience & BATCH_SIZE & DEVICE: {epochs} & {patience} & {BATCH_SIZE} & {DEVICE}')\n",
    "        \n",
    "        # initiate model\n",
    "        model = init_model(model_name)\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        # load loss\n",
    "        criterion = load_loss(loss_name)\n",
    "\n",
    "        # https://github.com/JunMa11/SegLossOdyssey/blob/master/losses_pytorch/hausdorff.py\n",
    "        \n",
    "        # Define optimiser\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = 1e-8)                    \n",
    "\n",
    "        # state to record result\n",
    "        state = {\n",
    "            'train_losses' : [], 'train_ious' : [], 'train_dices' : [], 'train_precisions' : [], 'train_recalls' : [], 'train_f1s' : [],\n",
    "            'val_losses' : [], 'val_ious' : [], 'val_dices' : [], 'val_precisions' : [], 'val_recalls' : [], 'val_f1s' : [],\n",
    "            'test_losses' : [], 'test_ious' : [], 'test_dices' : [], 'test_precisions' : [], 'test_recalls' : [], 'test_f1s' : [],\n",
    "            'best_val_dice' : 0,\n",
    "            'best_val_loss' : np.inf,\n",
    "            'best_epoch' : 0,\n",
    "            'best_net' : None,\n",
    "            'last_epoch' : -1\n",
    "        }    \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            model.train()\n",
    "            train_loss, train_num, train_iou, train_dice, train_precision, train_recall, train_f1 = 0, 0, 0, 0, 0, 0, 0\n",
    "            for i, (imgs, masks) in enumerate(dataloader_train):\n",
    "                imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "                \n",
    "                prediction = model(imgs)\n",
    "\n",
    "                # dict형태로 데이터가 들어오는 경우가 있음 ######################################################################\n",
    "                if isinstance(prediction, dict):\n",
    "                    prediction = torch.Tensor(prediction['out'])\n",
    "        \n",
    "                elif isinstance(prediction, tuple):\n",
    "                    prediction = torch.Tensor(prediction[0])\n",
    "                \n",
    "                else:\n",
    "                    prediction = prediction     \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "      \n",
    "                loss = criterion(prediction, masks)\n",
    "                    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_num += len(imgs)\n",
    "                train_iou += eval_segmentation(prediction, masks, metric='iou', batch_output=True).sum()\n",
    "                train_dice += eval_segmentation(prediction, masks, metric='dice', batch_output=True).sum()\n",
    "                train_precision += eval_segmentation(prediction, masks, metric='precision', batch_output=True).sum()\n",
    "                train_recall += eval_segmentation(prediction, masks, metric='recall', batch_output=True).sum()\n",
    "                train_f1 += eval_segmentation(prediction, masks, metric='f1', batch_output=True).sum()\n",
    "                print(\"\\r Epoch: {} of {}, Iter.: {} of {}, Train Loss: {:.6f}, Train IoU: {:.6f}, Train Dice:  {:.6f}\".format(epoch, epochs, i, len(dataloader_train), train_loss/(i+1), train_iou/train_num, train_dice/train_num), end=\"\")\n",
    "\n",
    "            # compute epoch-overall metric for train\n",
    "            epoch_train_loss = train_loss/len(dataloader_train)\n",
    "            epoch_train_iou = (train_iou/train_num).item()\n",
    "            epoch_train_dice = (train_dice/train_num).item()\n",
    "            epoch_train_precision = (train_precision/train_num).item()\n",
    "            epoch_train_recall = (train_recall/train_num).item()\n",
    "            epoch_train_f1 = (train_f1/train_num).item()\n",
    "                \n",
    "            # Validate\n",
    "            model.eval()\n",
    "            val_loss, val_num, val_iou, val_dice, val_precision, val_recall, val_f1 = 0, 0, 0, 0, 0, 0, 0\n",
    "            for i, (imgs, masks) in enumerate(dataloader_val):\n",
    "                imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "                \n",
    "                if len(imgs) != BATCH_SIZE:\n",
    "                    continue                \n",
    "                    \n",
    "                prediction = model(imgs)\n",
    "\n",
    "                # dict형태로 데이터가 들어오는 경우가 있음 ######################################################################\n",
    "                if isinstance(prediction, dict):\n",
    "                    prediction = torch.Tensor(prediction['out'])\n",
    "        \n",
    "                elif isinstance(prediction, tuple):\n",
    "                    prediction = torch.Tensor(prediction[0])\n",
    "                \n",
    "                else:\n",
    "                    prediction = prediction    \n",
    "                \n",
    "                loss = criterion(prediction, masks)\n",
    "                    \n",
    "                val_loss += loss.item()\n",
    "                val_num += len(imgs)\n",
    "                val_iou += eval_segmentation(prediction, masks, metric='iou', batch_output=True).sum()\n",
    "                val_dice += eval_segmentation(prediction, masks, metric='dice', batch_output=True).sum()\n",
    "                val_precision += eval_segmentation(prediction, masks, metric='precision', batch_output=True).sum()\n",
    "                val_recall += eval_segmentation(prediction, masks, metric='recall', batch_output=True).sum()\n",
    "                val_f1 += eval_segmentation(prediction, masks, metric='f1', batch_output=True).sum()\n",
    "\n",
    "            # compute epoch-overall metric for val        \n",
    "            epoch_val_loss = val_loss/len(dataloader_val)\n",
    "            epoch_val_iou = (val_iou/val_num).item()\n",
    "            epoch_val_dice = (val_dice/val_num).item()\n",
    "            epoch_val_precision = (val_precision/val_num).item()\n",
    "            epoch_val_recall = (val_recall/val_num).item()\n",
    "            epoch_val_f1 = (val_f1/val_num).item()\n",
    "\n",
    "            # Test\n",
    "            model.eval()\n",
    "            test_loss, test_num, test_iou, test_dice, test_precision, test_recall, test_f1 = 0, 0, 0, 0, 0, 0, 0\n",
    "            for i, (imgs, masks) in enumerate(dataloader_test):\n",
    "                imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
    "                \n",
    "                if len(imgs) != BATCH_SIZE:\n",
    "                    continue\n",
    "                    \n",
    "                prediction = model(imgs)\n",
    "\n",
    "                # dict형태로 데이터가 들어오는 경우가 있음 ######################################################################\n",
    "                if isinstance(prediction, dict):\n",
    "                    prediction = torch.Tensor(prediction['out'])\n",
    "        \n",
    "                elif isinstance(prediction, tuple):\n",
    "                    prediction = torch.Tensor(prediction[0])\n",
    "                \n",
    "                else:\n",
    "                    prediction = prediction   \n",
    "                \n",
    "                \n",
    "                loss = criterion(prediction, masks)\n",
    "                    \n",
    "                test_loss += loss.item()\n",
    "                test_num += len(imgs)\n",
    "                test_iou += eval_segmentation(prediction, masks, metric='iou', batch_output=True).sum()\n",
    "                test_dice += eval_segmentation(prediction, masks, metric='dice', batch_output=True).sum()\n",
    "                test_precision += eval_segmentation(prediction, masks, metric='precision', batch_output=True).sum()\n",
    "                test_recall += eval_segmentation(prediction, masks, metric='recall', batch_output=True).sum()\n",
    "                test_f1 += eval_segmentation(prediction, masks, metric='f1', batch_output=True).sum()\n",
    "           \n",
    "            # compute epoch-overall metric for test\n",
    "            epoch_test_loss = test_loss/len(dataloader_test)\n",
    "            epoch_test_iou = (test_iou/test_num).item()\n",
    "            epoch_test_dice = (test_dice/test_num).item()\n",
    "            epoch_test_precision = (test_precision/test_num).item()\n",
    "            epoch_test_recall = (test_recall/test_num).item()\n",
    "            epoch_test_f1 = (test_f1/test_num).item()\n",
    "\n",
    "            # print out the result\n",
    "            print(f\"\\r Epoch: {epoch} of {epochs}, \"+\n",
    "                  f\"Loss: {epoch_train_loss:.4f}/{epoch_val_loss:.4f}/{epoch_test_loss:.4f}, \"+\n",
    "                  f\"IoU: {epoch_train_iou:.4f}/{epoch_val_iou:.4f}/{epoch_test_iou:.4f}, \"+\n",
    "                  f\"Dice: {epoch_train_dice:.4f}/{epoch_val_dice:.4f}/{epoch_test_dice:.4f}\")\n",
    "            \n",
    "            # record the result\n",
    "            state['train_losses'].append(epoch_train_loss)\n",
    "            state['train_ious'].append(epoch_train_iou)\n",
    "            state['train_dices'].append(epoch_train_dice)\n",
    "            state['train_precisions'].append(epoch_train_precision)\n",
    "            state['train_recalls'].append(epoch_train_recall)\n",
    "            state['train_f1s'].append(epoch_train_f1)\n",
    "            state['val_losses'].append(epoch_val_loss)\n",
    "            state['val_ious'].append(epoch_val_iou)\n",
    "            state['val_dices'].append(epoch_val_dice)\n",
    "            state['val_precisions'].append(epoch_val_precision)\n",
    "            state['val_recalls'].append(epoch_val_recall)\n",
    "            state['val_f1s'].append(epoch_val_f1)            \n",
    "            state['test_losses'].append(epoch_test_loss)\n",
    "            state['test_ious'].append(epoch_test_iou)\n",
    "            state['test_dices'].append(epoch_test_dice)\n",
    "            state['test_precisions'].append(epoch_test_precision)\n",
    "            state['test_recalls'].append(epoch_test_recall)\n",
    "            state['test_f1s'].append(epoch_test_f1)                \n",
    "            state['last_epoch'] = epoch\n",
    "            \n",
    "            if epoch_val_dice >= state['best_val_dice']:\n",
    "                print(f'Saving.. {epoch} of {epochs}, best_val_dice improved from {state['best_val_dice']:.4f} to {epoch_val_dice:.4f}')\n",
    "                state['best_val_dice'] = epoch_val_dice\n",
    "                state['best_epoch'] = epoch\n",
    "\n",
    "                # state['best_net'] = model.state_dict()\n",
    "                # if not os.path.isdir('checkpoints'):\n",
    "                #     os.mkdir('checkpoints')\n",
    "                # torch.save(state, f'./checkpoints/ckpt_{model_name}_{data_name}.pth')\n",
    "            \n",
    "            elif epoch - state['best_epoch'] > patience:\n",
    "                print(f\"\\nEarly stopping. Target criteria has not improved for {patience} epochs.\\n\")\n",
    "                break\n",
    "        \n",
    "        # print(f'Validationset 기준 \\nBest_epoch:{best_epoch_dice}, Best_IOU:{best_iou:.4f}, Best_DiceScore:{best_dice:.4f}')\n",
    "        \n",
    "        fig, axs = plt.subplots(nrows=1, ncols=6, figsize=(18, 9))\n",
    "        for i, metric in enumerate(['losses','ious','dices','precisions','recalls','f1s']):\n",
    "            axs[i].plot(np.arange(state['last_epoch']+1), state['train_'+metric], label=f'Train, {metric}', linewidth=2, color='blue')\n",
    "            axs[i].plot(np.arange(state['last_epoch']+1), state['val_'+metric], label=f'Val, {metric}', linewidth=2, color='green')\n",
    "            axs[i].plot(np.arange(state['last_epoch']+1), state['test_'+metric], label=f'Test, {metric}', linewidth=2, color='orange')\n",
    "\n",
    "            # best_epoch 시점에 수직선 추가\n",
    "            axs[i].axvline(x=state['best_epoch'], color='r', linestyle='--', label=f'Best epoch : {state[\"best_epoch\"]}')\n",
    "            \n",
    "            # best_epoch에서의 train, val, test 값을 텍스트로 표시\n",
    "            best_train_value = state['train_' + metric][state['best_epoch']]\n",
    "            best_val_value = state['val_' + metric][state['best_epoch']]\n",
    "            best_test_value = state['test_' + metric][state['best_epoch']]\n",
    "        \n",
    "            # 각 점에 marker를 찍고 텍스트로 값 표시\n",
    "            axs[i].scatter(state['best_epoch'], best_train_value, color='blue', zorder=5)\n",
    "            axs[i].scatter(state['best_epoch'], best_val_value, color='green', zorder=5)\n",
    "            axs[i].scatter(state['best_epoch'], best_test_value, color='orange', zorder=5)\n",
    "        \n",
    "            # 텍스트로 표시\n",
    "            axs[i].annotate(f'Train: {best_train_value:.4f}', \n",
    "                            (state['best_epoch'], best_train_value), \n",
    "                            textcoords=\"offset points\", xytext=(0,10), ha='center', color='blue')\n",
    "            axs[i].annotate(f'Val: {best_val_value:.4f}', \n",
    "                            (state['best_epoch'], best_val_value), \n",
    "                            textcoords=\"offset points\", xytext=(0,10), ha='center', color='green')\n",
    "            axs[i].annotate(f'Test: {best_test_value:.4f}', \n",
    "                            (state['best_epoch'], best_test_value), \n",
    "                            textcoords=\"offset points\", xytext=(0,10), ha='center', color='orange')\n",
    "\n",
    "            axs[i].set_xlabel('Epoch')\n",
    "            axs[i].set_ylabel(metric)\n",
    "            axs[i].set_title(f'{metric}')\n",
    "            axs[i].legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "        if not os.path.isfile(result_file):\n",
    "            fp = open(result_file, 'w')\n",
    "            fp.write(','.join(['data_name',\n",
    "                           'model_name',\n",
    "                           'loss_name',\n",
    "                           'iter',\n",
    "                           'best_epoch',\n",
    "                           'test_iou',\n",
    "                           'test_dice',\n",
    "                           'test_precision',\n",
    "                           'test_recall',\n",
    "                           'test_f1'])+'\\n')\n",
    "        else:\n",
    "            fp = open(result_file, 'a')\n",
    "        best_epoch = state['best_epoch']\n",
    "        fp.write(','.join(map(str, [data_name,\n",
    "                           model_name,\n",
    "                           loss_name,\n",
    "                           iter,\n",
    "                           best_epoch,\n",
    "                           state['test_ious'][best_epoch],\n",
    "                           state['test_dices'][best_epoch],\n",
    "                           state['test_precisions'][best_epoch],\n",
    "                           state['test_recalls'][best_epoch],\n",
    "                           state['test_f1s'][best_epoch]]))+'\\n')\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_losses = [\n",
    "        \"IoUWithGaussianLoss\",\n",
    "        \"BCEWithGaussianLoss\",\n",
    "        \"DiceWithGaussianLoss\",\n",
    "        \"FocalWithGaussianLoss\",\n",
    "        \n",
    "        \"FocalWithSSIMLoss\",\n",
    "        \"IoUWithSSIMLoss\" ,\n",
    "        \"DiceWithSSIMLoss\"  ,\n",
    "        \"BCEWithSSIMLoss\"  ,\n",
    "        \n",
    "        \"FocalWithContextualLoss\" ,\n",
    "        \"BCEWithContextualLoss\" ,\n",
    "        \"IoUWithContextualLoss\"  ,\n",
    "        \"DiceWithContextualLoss\"  ,\n",
    "        \n",
    "        \"IoUWithTVLoss_tar\" ,\n",
    "        \"FocalWithTVLoss_tar\"  ,\n",
    "        \"DiceWithTVLoss_tar\"  ,\n",
    "        \"BCEWithTVLoss_tar\" ,\n",
    "        \n",
    "        \n",
    "        \"FocalWithEdgeLoss\" ,\n",
    "        \"BCEWithEdgeLoss\" ,\n",
    "        \"IoUWithEdgeLoss\" ,\n",
    "        \"DiceWithEdgeLoss\"  ,\n",
    "        \n",
    "    \n",
    "        'IoULoss' ,\n",
    "        'DiceLoss', \n",
    "        'BCELoss' ,\n",
    "        'FocalLoss' ,\n",
    "        'IoUDiceLoss' ,\n",
    "        'IoUBCELoss' ,\n",
    "        'IoUFocalLoss' ,\n",
    "        'DiceBCELoss' ,\n",
    "        'DiceFocalLoss' ,\n",
    "        'BCEFocalLoss' ,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data names\n",
    "data_names = ['CVC-ClinicDB', 'ISIC', 'Kvasir-SEG', 'breast-cancer-benign', 'breast-cancer-malignant', 'wound']\n",
    "\n",
    "# models name\n",
    "models = ['ColonFormer','FCN','DuckNet','UNet++','Unet','ESFPNet','DeepLab_V3+','ColonSegNet','EMCADNet','FCBFormer','caranet','FAT_Net'] \n",
    "\n",
    "iters = list(np.arange(0,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # from nnunet import Nested_UNet as UNet2p\n",
    "        # model = UNet2p(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_names: ['CVC-ClinicDB', 'ISIC', 'Kvasir-SEG', 'breast-cancer-benign', 'breast-cancer-malignant', 'wound']\n",
      "models: ['ColonFormer', 'FCN', 'DuckNet', 'UNet++', 'Unet', 'ESFPNet', 'DeepLab_V3+', 'ColonSegNet', 'EMCADNet', 'FCBFormer', 'caranet', 'FAT_Net']\n",
      "iters: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(f'data_names: {data_names}')\n",
    "print(f'models: {models}')\n",
    "print(f'iters: {iters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/ahnailab/jsj0414/losses_research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ['CVC-ClinicDB', 'ISIC', 'Kvasir-SEG', 'breast-cancer-benign', 'breast-cancer-malignant', 'wound']\u001b[39;00m\n\u001b[1;32m      2\u001b[0m run_env \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_names\u001b[39m\u001b[38;5;124m'\u001b[39m :  [\u001b[38;5;28mstr\u001b[39m(data) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_names],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_names\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;28mstr\u001b[39m(model) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_file\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m run(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_env)\n",
      "Cell \u001b[0;32mIn[38], line 25\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(data_names, model_names, loss_names, iters, split_ratio, base_random_seed, epochs, patience, BATCH_SIZE, result_file)\u001b[0m\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_images, val_images, test_images, train_labels, val_labels, test_labels \u001b[38;5;241m=\u001b[39m load_data(data_name, split_ratio\u001b[38;5;241m=\u001b[39msplit_ratio, random_seed\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[1;32m     27\u001b[0m custom_dataset_train \u001b[38;5;241m=\u001b[39m myDataSet(train_images, train_labels, transforms\u001b[38;5;241m=\u001b[39mtest_transforms)\n\u001b[1;32m     28\u001b[0m custom_dataset_val \u001b[38;5;241m=\u001b[39m myDataSet(val_images, val_labels, transforms\u001b[38;5;241m=\u001b[39mtest_transforms)\n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_name, split_ratio, random_seed)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split_ratio) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:  \u001b[38;5;66;03m# split_ratio = (train, validation, test)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     trainval2test_size \u001b[38;5;241m=\u001b[39m split_ratio[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(split_ratio)\n\u001b[0;32m---> 15\u001b[0m     trainval_images, test_images, trainval_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(image_files, label_files, test_size\u001b[38;5;241m=\u001b[39mtrainval2test_size, random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[1;32m     16\u001b[0m     train2val_size \u001b[38;5;241m=\u001b[39m split_ratio[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(split_ratio[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     17\u001b[0m     train_images, val_images, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(trainval_images, trainval_labels, test_size\u001b[38;5;241m=\u001b[39mtrain2val_size, random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n",
      "File \u001b[0;32m~/.conda/envs/image/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/image/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2853\u001b[0m )\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/image/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# ['CVC-ClinicDB', 'ISIC', 'Kvasir-SEG', 'breast-cancer-benign', 'breast-cancer-malignant', 'wound']\n",
    "run_env = {\n",
    "    'data_names' :  [str(data) for data in data_names],\n",
    "    'model_names' : [str(model) for model in models],\n",
    "    'loss_names' : [str(loss) for loss in all_losses],\n",
    "    'iters' : [int(it) for it in iters],\n",
    "    'split_ratio' : [0.6, 0.2, 0.2],\n",
    "    'base_random_seed' : 42,  \n",
    "    'epochs' : 200,\n",
    "    'patience' : 40,\n",
    "    'BATCH_SIZE' : 8,\n",
    "    'result_file' : './result.csv'\n",
    "}\n",
    "\n",
    "run(**run_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에 에러는 현재 데이터른 다른 곳으로 옮겨두어 생긴 에러니 염려하지 않으셔도 됩니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "image (py3.12)",
   "language": "python",
   "name": "image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
